# ComfyUI Integration Architecture

## Overview

This document describes the deep integration between DiffusionToolkit and ComfyUI, enabling a seamless workflow for image discovery, refinement, replication, and enhancement. The integration leverages DiffusionToolkit's 5-layer embedding system and PostgreSQL database to provide intelligent image operations that no standalone ComfyUI setup can achieve.

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [5-Layer Embedding System](#5-layer-embedding-system)
3. [Luna Node Pack Integration](#luna-node-pack-integration)
4. [DiffusionToolkit API Endpoints](#diffusiontoolkit-api-endpoints)
5. [Suggested Custom Nodes](#suggested-custom-nodes)
6. [Feature Implementations](#feature-implementations)
7. [Data Flow Diagrams](#data-flow-diagrams)

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DiffusionToolkit Ecosystem                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    DiffusionToolkit (WPF Application)                   â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Image Browser & Search                                            â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Embedding Generation (BGE, CLIP-L, CLIP-G, CLIP-H)               â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Character Discovery & Clustering                                  â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Prompt Engine / Wildcard Editor                                   â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Expression Pack Creator                                           â”‚ â”‚
â”‚  â”‚  â””â”€â”€ REST API Server (for ComfyUI nodes)                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                         â”‚
â”‚                          REST API / WebSocket                                â”‚
â”‚                                    â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         Background Services                             â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Diffusion.Watcher (File indexing, metadata extraction)           â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Luna Daemon (Shared VAE/CLIP on dedicated GPU)                   â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Face Detection Service (YOLO + CLIP-H embeddings)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                         â”‚
â”‚                            PostgreSQL + pgvector                             â”‚
â”‚                                    â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    ComfyUI + Luna Node Pack                            â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ LunaToolkitLoader (fetch images/data from DiffusionToolkit)      â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ LunaConfigGateway (central parameter hub)                        â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ LunaPromptCraft (intelligent wildcard resolution)                â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Luna Upscalers (Simple, Advanced, Ultimate SD)                   â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ LunaMultiSaver (metadata-aware saving)                           â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Luna Daemon nodes (shared VRAM)                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Principles

1. **DiffusionToolkit is the brain** - All image metadata, embeddings, and discovery live here
2. **ComfyUI is the muscle** - All image generation, refinement, and processing happens here
3. **Luna Daemon is shared memory** - VAE/CLIP models loaded once, used by all instances
4. **PostgreSQL is the memory** - Persistent, queryable, vector-searchable storage

---

## 5-Layer Embedding System

DiffusionToolkit generates 5 distinct embeddings for each image, enabling different types of similarity search and matching:

### Layer Architecture

| Layer | Model | Dimensions | Purpose | Use Case |
|-------|-------|------------|---------|----------|
| **1. BGE Prompt** | BGE-large-en-v1.5 | 1024 | Semantic text understanding | "Find images with similar concepts" |
| **2. BGE Negative** | BGE-large-en-v1.5 | 1024 | Negative prompt matching | "Find images avoiding similar things" |
| **3. CLIP-L** | CLIP ViT-L/14 | 768 | SDXL text encoder (first) | "Match SDXL prompt interpretation" |
| **4. CLIP-G** | CLIP ViT-bigG/14 | 1280 | SDXL text encoder (second) | "Match SDXL composition/style" |
| **5. CLIP-H** | CLIP ViT-H/14 | 1280 | Visual similarity | "Find visually similar images" |

### How Each Layer Enhances ComfyUI Workflows

#### Layer 1: BGE Prompt Embedding (Semantic Search)
```
User Query: "cyberpunk girl with neon lights"
     â”‚
     â–¼
BGE encodes query â†’ Search prompt_embedding column
     â”‚
     â–¼
Returns: Images whose prompts are semantically similar
         (even if they used different words like "sci-fi woman, glowing signs")
```

**ComfyUI Integration:**
- "Find reference images for this concept"
- "Show me successful prompts similar to what I'm trying"
- Feed results into IP-Adapter or ControlNet

#### Layer 2: BGE Negative Embedding
```
Your Negative: "blurry, deformed, watermark"
     â”‚
     â–¼
Search images that successfully avoided these issues
     â”‚
     â–¼
Returns: High-quality images with effective negative prompts
```

**ComfyUI Integration:**
- "What negative prompts work well for this style?"
- Auto-suggest negatives based on similar successful images

#### Layer 3: CLIP-L Embedding (SDXL Text Encoder 1)
```
Your Prompt â†’ CLIP-L encoding â†’ Match against stored CLIP-L embeddings
     â”‚
     â–¼
Find images where SDXL's first text encoder interpreted the prompt similarly
```

**ComfyUI Integration:**
- Style matching: "Find images with similar SDXL style interpretation"
- Debug: "Why does my prompt look different than expected?"
- Cross-reference: "What other prompts produce this CLIP-L pattern?"

#### Layer 4: CLIP-G Embedding (SDXL Text Encoder 2)
```
Your Prompt â†’ CLIP-G encoding â†’ Match against stored CLIP-G embeddings
     â”‚
     â–¼
Find images with similar composition, color palette, overall aesthetic
```

**ComfyUI Integration:**
- Composition matching: "Find images with similar layout/structure"
- Color palette discovery: "Images with this color mood"
- SDXL-specific tuning: "How CLIP-G interprets my concepts"

#### Layer 5: CLIP-H Visual Embedding (Image Similarity)
```
Your Image â†’ CLIP-H encoding â†’ Match against stored CLIP-H embeddings
     â”‚
     â–¼
Find visually similar images regardless of how they were prompted
```

**ComfyUI Integration:**
- "Find more images that look like this"
- Character discovery: "All images of this face/character"
- Style transfer: "Images with this visual style for IP-Adapter"
- Training data curation: "Similar images for LoRA dataset"

### Cross-Layer Queries

The power comes from combining layers:

```sql
-- "Find images that look similar AND were prompted similarly"
SELECT * FROM images
WHERE 
    -- Visual similarity (CLIP-H)
    image_embedding <=> $visual_query < 0.3
    AND
    -- Semantic similarity (BGE)
    prompt_embedding <=> $semantic_query < 0.4
ORDER BY 
    (image_embedding <=> $visual_query) + 
    (prompt_embedding <=> $semantic_query)
LIMIT 20;
```

```sql
-- "Find images with this composition but different subject"
SELECT * FROM images
WHERE
    -- Similar composition (CLIP-G)
    clip_g_embedding <=> $composition_query < 0.2
    AND
    -- Different semantics (BGE)
    prompt_embedding <=> $subject_query > 0.5
```

---

## Luna Node Pack Integration

### Existing Nodes & Their Role

#### LunaConfigGateway
**Role:** Central parameter hub that outputs complete metadata

```
Inputs:
â”œâ”€â”€ model, clip, vae
â”œâ”€â”€ positive/negative prompts
â”œâ”€â”€ width, height, batch_size
â”œâ”€â”€ seed, steps, cfg, denoise
â”œâ”€â”€ clip_skip, sampler, scheduler
â””â”€â”€ lora_stack (optional)

Outputs:
â”œâ”€â”€ model, clip, vae (LoRA-modified)
â”œâ”€â”€ positive, negative (encoded)
â”œâ”€â”€ latent (empty, sized)
â”œâ”€â”€ All input values (passthrough)
â”œâ”€â”€ lora_stack (merged)
â””â”€â”€ metadata â† THIS IS KEY
```

**Integration:** DiffusionToolkit intercepts the `metadata` output to:
- Store complete generation parameters with saved images
- Enable perfect replication of any image
- Build analytics on what settings produce highly-rated results

#### LunaBatchPromptExtractor / Loader
**Role:** Bridge between DiffusionToolkit's database and ComfyUI

**Current:** Reads/writes JSON files

**Enhanced:** Direct database integration
```
DiffusionToolkit exports selected images â†’ JSON format
LunaBatchPromptLoader reads â†’ Iterates through for batch generation
```

#### LunaPromptCraft
**Role:** Intelligent wildcard resolution with LoRA linking

**Integration with DiffusionToolkit:**
- Sync YAML wildcard files via database (versioned)
- LoRA usage analytics feed back into connection suggestions
- Error detection shown in both UIs

#### Luna Upscalers
**Role:** Image enhancement pipeline

**Integration:**
- DiffusionToolkit queues images for upscaling
- ComfyUI processes via Luna Ultimate SD Upscale
- Results saved back with upscale metadata

#### LunaMultiSaver
**Role:** Save images with complete metadata

**Integration:**
- Receives `metadata` from LunaConfigGateway
- Embeds in PNG/WebP
- DiffusionToolkit's Watcher indexes automatically
- Full round-trip: generate â†’ save â†’ index â†’ searchable

#### Luna Daemon
**Role:** Shared VAE/CLIP across instances

**Integration:**
- Runs as Windows service alongside Diffusion.Watcher
- DiffusionToolkit's embedding generation uses same daemon
- Single VRAM allocation for VAE/CLIP, shared by all

---

## DiffusionToolkit API Endpoints

New REST API endpoints for ComfyUI custom nodes to query:

### Image Retrieval

#### `GET /api/images/similar`
Find similar images using any embedding layer.

```json
// Request
{
    "query_type": "visual" | "semantic" | "composition" | "style",
    "query_image": "base64 or path",  // for visual
    "query_text": "prompt text",       // for semantic
    "limit": 20,
    "min_rating": 3,                   // optional: only rated images
    "folder_filter": ["path/to/folder"], // optional
    "exclude_ids": [123, 456]          // optional: exclude specific images
}

// Response
{
    "images": [
        {
            "id": 789,
            "path": "D:/Images/image001.png",
            "thumbnail_base64": "...",
            "similarity": 0.92,
            "prompt": "original prompt...",
            "negative_prompt": "...",
            "metadata": { ... }
        }
    ]
}
```

#### `GET /api/images/{id}`
Get full image data and metadata.

```json
// Response
{
    "id": 789,
    "path": "D:/Images/image001.png",
    "image_base64": "...",  // full image
    "prompt": "...",
    "negative_prompt": "...",
    "width": 1024,
    "height": 1024,
    "seed": 12345,
    "steps": 20,
    "cfg": 7.0,
    "sampler": "euler",
    "scheduler": "normal",
    "model": "illustrious_v1",
    "loras": [
        {"name": "style_lora", "weight": 0.8}
    ],
    "rating": 5,
    "tags": ["favorite", "portfolio"],
    "embeddings": {
        "prompt_bge": [...],      // 1024D
        "clip_l": [...],          // 768D
        "clip_g": [...],          // 1280D
        "image_clip_h": [...]     // 1280D
    }
}
```

#### `GET /api/images/{id}/regions`
Get detected face/body regions for an image.

```json
// Response
{
    "image_id": 789,
    "regions": [
        {
            "id": 1001,
            "type": "face",
            "bbox": {"x": 100, "y": 50, "width": 200, "height": 200},
            "confidence": 0.95,
            "cluster_id": 47,
            "cluster_name": "Luna",
            "crop_base64": "..."  // cropped region
        }
    ]
}
```

### Character/Cluster Queries

#### `GET /api/clusters`
List all discovered character clusters.

```json
// Response
{
    "clusters": [
        {
            "id": 47,
            "name": "Luna",
            "auto_name": "Character_0047",
            "member_count": 847,
            "avg_confidence": 0.94,
            "centroid_thumbnail": "base64..."
        }
    ]
}
```

#### `GET /api/clusters/{id}/images`
Get all images containing a specific character.

```json
// Request params
?limit=50&offset=0&min_quality=3&sort=confidence

// Response
{
    "cluster_id": 47,
    "cluster_name": "Luna",
    "total_count": 847,
    "images": [
        {
            "id": 789,
            "path": "...",
            "thumbnail_base64": "...",
            "face_bbox": {...},
            "confidence": 0.98,
            "quality_rating": 5
        }
    ]
}
```

### Prompt & Wildcard

#### `GET /api/wildcards`
Get available wildcard categories.

```json
// Response
{
    "yaml_wildcards": [
        {
            "name": "body",
            "path": "body.yaml",
            "categories": ["hair", "eyes", "skin", "body_type"],
            "template_count": 15
        }
    ],
    "text_wildcards": [
        {"name": "colors", "path": "__colors__.txt", "entry_count": 50}
    ]
}
```

#### `POST /api/wildcards/resolve`
Resolve a wildcard template.

```json
// Request
{
    "template": "{body} wearing {clothing:casual}",
    "seed": 12345,
    "count": 10  // generate 10 variations
}

// Response
{
    "resolutions": [
        "1girl with long blonde hair wearing jeans and t-shirt",
        "1girl with short black hair wearing sundress",
        ...
    ],
    "lora_suggestions": [
        {"name": "casual_fashion", "weight": 0.6, "trigger": "casual style"}
    ]
}
```

### ControlNet Preprocessing

#### `GET /api/images/{id}/controlnet/{type}`
Get preprocessed ControlNet images.

```json
// Request
GET /api/images/789/controlnet/openpose

// Response
{
    "image_id": 789,
    "controlnet_type": "openpose",
    "preprocessed_base64": "...",
    "cached": true,
    "generated_at": "2025-12-03T10:30:00Z"
}

// Supported types:
// - openpose, openpose_face, openpose_hand, openpose_full
// - canny, depth_midas, depth_zoe
// - normal_bae, lineart, lineart_anime
// - softedge, scribble, segmentation
```

#### `POST /api/images/{id}/controlnet/batch`
Generate multiple ControlNet preprocessings.

```json
// Request
{
    "types": ["openpose", "depth_midas", "canny"],
    "cache": true
}

// Response
{
    "results": {
        "openpose": {"success": true, "base64": "..."},
        "depth_midas": {"success": true, "base64": "..."},
        "canny": {"success": true, "base64": "..."}
    }
}
```

### Caption & Tag Generation

#### `GET /api/images/{id}/caption`
Get or generate captions/tags.

```json
// Response
{
    "image_id": 789,
    "captions": {
        "sidecar_txt": "original sidecar content if exists",
        "wd14_tags": ["1girl", "long_hair", "blue_eyes", ...],
        "blip2_caption": "A woman with long blonde hair...",
        "joycaption": "Detailed natural language description..."
    },
    "generated_at": "2025-12-03T10:30:00Z"
}
```

#### `POST /api/images/{id}/caption/generate`
Generate new captions using specific models.

```json
// Request
{
    "models": ["wd14", "joycaption"],
    "wd14_threshold": 0.35,
    "joycaption_mode": "descriptive"
}
```

### Batch Operations

#### `POST /api/batch/export`
Export images for LoRA training or batch processing.

```json
// Request
{
    "image_ids": [789, 790, 791, ...],
    "format": "kohya" | "comfyui_batch" | "luna_loader",
    "include_captions": true,
    "caption_format": "txt_sidecar" | "json",
    "output_path": "D:/Training/character_luna"
}

// Response
{
    "success": true,
    "exported_count": 50,
    "output_path": "D:/Training/character_luna",
    "manifest": "D:/Training/character_luna/manifest.json"
}
```

#### `POST /api/batch/queue`
Queue images for ComfyUI processing.

```json
// Request
{
    "image_ids": [789, 790, 791],
    "workflow": "upscale_and_fix",
    "parameters": {
        "upscale_factor": 2.0,
        "denoise": 0.55,
        "face_fix": true
    }
}

// Response
{
    "queue_id": "batch_001",
    "queued_count": 3,
    "estimated_time": "5 minutes"
}
```

---

## Suggested Custom Nodes

Beyond your existing Luna nodes, these would complete the integration:

### 1. LunaToolkitImageLoader
**Purpose:** Load images directly from DiffusionToolkit database

```python
class LunaToolkitImageLoader:
    """
    Load image from DiffusionToolkit by ID, path, or similarity search
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "query_mode": (["by_id", "by_path", "similar_visual", "similar_prompt", "random_from_cluster"],),
            },
            "optional": {
                "image_id": ("INT", {"default": 0}),
                "image_path": ("STRING", {"default": ""}),
                "query_image": ("IMAGE",),
                "query_text": ("STRING", {"default": ""}),
                "cluster_id": ("INT", {"default": 0}),
                "min_rating": ("INT", {"default": 0, "min": 0, "max": 5}),
                "limit": ("INT", {"default": 1, "min": 1, "max": 100}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "INT", "TOOLKIT_METADATA")
    RETURN_NAMES = ("image", "prompt", "negative", "seed", "metadata")
    
    def load(self, query_mode, **kwargs):
        # Query DiffusionToolkit API
        response = requests.get(f"{TOOLKIT_API}/images/query", params={...})
        # Return image and metadata
```

**Use Cases:**
- "Load a random highly-rated image from character cluster 47"
- "Find an image visually similar to this one for reference"
- "Get the prompt that generated this image for modification"

### 2. LunaToolkitSimilaritySearch
**Purpose:** Multi-layer similarity search with UI preview

```python
class LunaToolkitSimilaritySearch:
    """
    Search DiffusionToolkit database using multiple embedding layers
    Returns grid of similar images for user selection
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "query_image": ("IMAGE",),
                "search_layers": (["visual_only", "semantic_only", "combined", "composition"],),
                "result_count": ("INT", {"default": 9, "min": 1, "max": 25}),
            },
            "optional": {
                "query_text": ("STRING", {"default": ""}),
                "weight_visual": ("FLOAT", {"default": 0.5, "min": 0, "max": 1}),
                "weight_semantic": ("FLOAT", {"default": 0.5, "min": 0, "max": 1}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "IMAGE", "STRING", "TOOLKIT_METADATA")
    RETURN_NAMES = ("selected_image", "all_results", "selected_prompt", "metadata")
```

### 3. LunaToolkitControlNetCache
**Purpose:** Fetch or generate cached ControlNet preprocessings

```python
class LunaToolkitControlNetCache:
    """
    Get ControlNet preprocessing from DiffusionToolkit cache
    Avoids redundant preprocessing for images already in database
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_id": ("INT",),
                "controlnet_type": ([
                    "openpose", "openpose_full", "depth_midas", "depth_zoe",
                    "canny", "lineart", "lineart_anime", "softedge", "normal_bae"
                ],),
                "generate_if_missing": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "BOOLEAN")
    RETURN_NAMES = ("controlnet_image", "was_cached")
```

**Benefits:**
- No redundant preprocessing for database images
- Instant ControlNet for any indexed image
- Background pre-generation for popular images

### 4. LunaToolkitCharacterSampler
**Purpose:** Sample images from a character cluster for training/reference

```python
class LunaToolkitCharacterSampler:
    """
    Get representative images from a character cluster
    For LoRA training, expression packs, or style reference
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "cluster_name_or_id": ("STRING", {"default": ""}),
                "sample_count": ("INT", {"default": 10, "min": 1, "max": 100}),
                "sample_strategy": (["random", "diverse", "highest_quality", "highest_confidence"],),
                "min_quality": ("INT", {"default": 3, "min": 1, "max": 5}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "INT")
    RETURN_NAMES = ("images", "prompts", "count")
```

### 5. LunaToolkitCaptionFetcher
**Purpose:** Get captions/tags from database or generate on-demand

```python
class LunaToolkitCaptionFetcher:
    """
    Fetch or generate captions for images
    Supports multiple caption formats
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_id": ("INT",),
                "caption_type": (["sidecar", "wd14", "blip2", "joycaption", "combined"],),
            },
            "optional": {
                "generate_if_missing": ("BOOLEAN", {"default": True}),
                "wd14_threshold": ("FLOAT", {"default": 0.35}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("caption", "tags")
```

### 6. LunaToolkitBatchQueue
**Purpose:** Queue multiple images for processing with progress tracking

```python
class LunaToolkitBatchQueue:
    """
    Send batch of images to DiffusionToolkit queue
    For upscaling, face fixing, or other batch operations
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_ids": ("STRING", {"default": ""}),  # comma-separated or range
                "operation": (["upscale", "face_fix", "regenerate", "custom"],),
            },
            "optional": {
                "workflow_name": ("STRING", {"default": ""}),
                "parameters": ("STRING", {"default": "{}"}),  # JSON
            }
        }
    
    RETURN_TYPES = ("STRING", "INT")
    RETURN_NAMES = ("queue_id", "queued_count")
```

### 7. LunaToolkitMetadataWriter
**Purpose:** Write generation metadata back to DiffusionToolkit

```python
class LunaToolkitMetadataWriter:
    """
    Update image metadata in DiffusionToolkit after processing
    Tracks upscale history, refinement passes, etc.
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_id": ("INT",),
                "metadata": ("TOOLKIT_METADATA",),
                "operation_type": (["upscale", "face_fix", "inpaint", "regenerate"],),
            },
            "optional": {
                "new_image": ("IMAGE",),
                "save_as_new": ("BOOLEAN", {"default": False}),
            }
        }
```

### 8. LunaExpressionPackGenerator
**Purpose:** Generate character expression packs using cluster data

```python
class LunaExpressionPackGenerator:
    """
    Generate expression pack for a character cluster
    Uses reference images + ControlNet poses + face swapping
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "cluster_id": ("INT",),
                "expression_set": (["standard_16", "extended_32", "custom"],),
                "model": ("MODEL",),
                "clip": ("CLIP",),
                "vae": ("VAE",),
            },
            "optional": {
                "custom_expressions": ("STRING", {"default": ""}),
                "face_swap_strength": ("FLOAT", {"default": 0.8}),
                "ip_adapter_weight": ("FLOAT", {"default": 0.7}),
                "output_format": (["sillytavern", "individual", "grid"],),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("expression_pack", "manifest_json")
```

---

## Feature Implementations

### 1. Right-Click "Send to ComfyUI"

**DiffusionToolkit UI:**
```
Right-click image â†’ "Send to ComfyUI" â†’ Submenu:
â”œâ”€â”€ "Upscale (2x)"
â”œâ”€â”€ "Upscale (4x)"
â”œâ”€â”€ "Fix Faces"
â”œâ”€â”€ "Regenerate Similar"
â”œâ”€â”€ "Use as ControlNet Reference"
â”œâ”€â”€ "Use as IP-Adapter Reference"
â”œâ”€â”€ "Add to Expression Pack Queue"
â””â”€â”€ "Custom Workflow..."
```

**Implementation:**
1. DiffusionToolkit sends image ID + operation to local API
2. API constructs workflow JSON with appropriate Luna nodes
3. Workflow submitted to ComfyUI queue
4. Progress shown in DiffusionToolkit status bar
5. Result saved and indexed automatically

### 2. Character Discovery â†’ Expression Pack

**Workflow:**
```
Character cluster selected in DiffusionToolkit
     â”‚
     â–¼
User clicks "Create Expression Pack"
     â”‚
     â–¼
Dialog: Select expressions, output format, settings
     â”‚
     â–¼
DiffusionToolkit fetches best reference images from cluster
     â”‚
     â–¼
Sends to ComfyUI via LunaExpressionPackGenerator
     â”‚
     â”œâ”€â”€ Loads reference images
     â”œâ”€â”€ Generates expression prompts (LunaExpressionPromptBuilder)
     â”œâ”€â”€ Applies ControlNet poses
     â”œâ”€â”€ IP-Adapter style transfer
     â”œâ”€â”€ InsightFace identity swap
     â””â”€â”€ Saves with LunaExpressionSlicerSaver
     â”‚
     â–¼
Expression pack saved to SillyTavern folder
```

### 3. Batch Fix Workflow

**Queue Processing:**
```
User marks 127 images with ğŸ”§ (needs fix) in cluster view
     â”‚
     â–¼
Clicks "Batch Fix Faces" â†’ Settings dialog
     â”‚
     â–¼
DiffusionToolkit queues to /api/batch/queue
     â”‚
     â–¼
Background worker iterates:
â”œâ”€â”€ Load image from database (LunaToolkitImageLoader)
â”œâ”€â”€ Detect face region (cached in face_regions table)
â”œâ”€â”€ Apply inpaint mask to face area
â”œâ”€â”€ Run img2img at specified denoise (0.45-0.65)
â”œâ”€â”€ Optionally upscale if face < 512px
â”œâ”€â”€ Save result (LunaMultiSaver)
â”œâ”€â”€ Update database with new path/metadata
â””â”€â”€ Re-generate CLIP-H embedding for updated face
     â”‚
     â–¼
Progress shown in DiffusionToolkit UI
```

### 4. Prompt Engine Sync

**Bidirectional Sync:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      YAML Wildcard Files                         â”‚
â”‚  â”œâ”€â”€ body.yaml                                                   â”‚
â”‚  â”œâ”€â”€ clothing.yaml                                               â”‚
â”‚  â””â”€â”€ locations.yaml                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
                    Git-style versioning
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PostgreSQL (wildcards table)                   â”‚
â”‚  â”œâ”€â”€ id, name, content, version, created_at                     â”‚
â”‚  â””â”€â”€ Conflict resolution: latest wins, history preserved        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
                         REST API
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Both UIs see the same wildcard data                   â”‚
â”‚  â”œâ”€â”€ DiffusionToolkit Prompt Engine                             â”‚
â”‚  â””â”€â”€ ComfyUI LunaPromptCraft node                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. LoRA Training Export

**From Character Cluster:**
```
Cluster "Luna" (847 images) â†’ Export for Training
     â”‚
     â–¼
Filter: Quality â‰¥ 4, Exclude marked bad
     â”‚
     â–¼
Result: 623 images selected
     â”‚
     â–¼
Export Options:
â”œâ”€â”€ Format: Kohya / EveryDream / Flux
â”œâ”€â”€ Caption source: Sidecar / Generated / Prompt-based
â”œâ”€â”€ Include: Full images / Face crops / Both
â”œâ”€â”€ Regularization: Auto-generate from similar non-character images
â””â”€â”€ Output: D:/Training/Luna_LoRA/
     â”‚
     â–¼
Export Structure:
â”œâ”€â”€ Luna_LoRA/
â”‚   â”œâ”€â”€ 10_Luna/
â”‚   â”‚   â”œâ”€â”€ image001.png
â”‚   â”‚   â”œâ”€â”€ image001.txt (caption)
â”‚   â”‚   â”œâ”€â”€ image002.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 1_regularization/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ training_config.toml
```

---

## Data Flow Diagrams

### Complete Generation â†’ Index â†’ Search Cycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        GENERATION PHASE                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  LunaPromptCraft                LunaConfigGateway                        â”‚
â”‚       â”‚                              â”‚                                    â”‚
â”‚       â–¼                              â–¼                                    â”‚
â”‚  Resolved Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Parameters + Encoding                   â”‚
â”‚                                      â”‚                                    â”‚
â”‚                                      â–¼                                    â”‚
â”‚                               [KSampler]                                  â”‚
â”‚                                      â”‚                                    â”‚
â”‚                                      â–¼                                    â”‚
â”‚                             LunaMultiSaver                                â”‚
â”‚                                      â”‚                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                    â–¼                 â–¼                 â–¼                 â”‚
â”‚              image.png         metadata.json     workflow.json           â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INDEXING PHASE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  Diffusion.Watcher detects new file                                      â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Quick Scan (path, size, dates) â†’ images table                           â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Metadata Extraction:                                                     â”‚
â”‚  â”œâ”€â”€ Read PNG/EXIF metadata                                              â”‚
â”‚  â”œâ”€â”€ Parse prompt, negative, parameters                                  â”‚
â”‚  â”œâ”€â”€ Extract LoRAs, ControlNets, workflow                                â”‚
â”‚  â””â”€â”€ Store in images table                                               â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Embedding Generation (GPU):                                             â”‚
â”‚  â”œâ”€â”€ BGE: prompt â†’ 1024D                                                 â”‚
â”‚  â”œâ”€â”€ BGE: negative â†’ 1024D                                               â”‚
â”‚  â”œâ”€â”€ CLIP-L: prompt â†’ 768D                                               â”‚
â”‚  â”œâ”€â”€ CLIP-G: prompt â†’ 1280D                                              â”‚
â”‚  â””â”€â”€ CLIP-H: image â†’ 1280D                                               â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Face Detection:                                                          â”‚
â”‚  â”œâ”€â”€ YOLO/InsightFace â†’ bbox coordinates                                 â”‚
â”‚  â”œâ”€â”€ Crop face regions                                                   â”‚
â”‚  â”œâ”€â”€ CLIP-H: face â†’ 1280D (per face)                                     â”‚
â”‚  â””â”€â”€ Store in face_regions table                                         â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Cluster Assignment:                                                      â”‚
â”‚  â””â”€â”€ Match face embedding to existing clusters                           â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          SEARCH PHASE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  User in DiffusionToolkit:                                               â”‚
â”‚  "Find images similar to this one with rating â‰¥ 4"                       â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Query Construction:                                                      â”‚
â”‚  â”œâ”€â”€ CLIP-H encode query image â†’ 1280D                                   â”‚
â”‚  â”œâ”€â”€ Vector similarity search on image_embedding                          â”‚
â”‚  â”œâ”€â”€ Filter: rating >= 4                                                 â”‚
â”‚  â””â”€â”€ Return top 20                                                        â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Results displayed in grid                                                â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  User selects image â†’ Right-click "Send to ComfyUI"                      â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  LOOP BACK TO GENERATION PHASE                                           â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Character Discovery Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FACE DETECTION (Per Image)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  Image from database                                                      â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  YOLO Face Detector                                                       â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â”œâ”€â”€ Face 1: bbox(100, 50, 200, 200), conf: 0.95                    â”‚
â”‚       â”œâ”€â”€ Face 2: bbox(400, 80, 180, 180), conf: 0.87                    â”‚
â”‚       â””â”€â”€ (multiple faces per image possible)                             â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼ (for each face)                                                   â”‚
â”‚  Crop face + padding                                                      â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  CLIP-H Vision Encoder                                                    â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  1280D embedding stored in face_regions                                   â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    (after N images processed)
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLUSTERING (Batch)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  Fetch all unclustered face embeddings                                    â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  HDBSCAN Clustering                                                       â”‚
â”‚  â”œâ”€â”€ min_cluster_size: 10                                                â”‚
â”‚  â”œâ”€â”€ metric: cosine                                                       â”‚
â”‚  â””â”€â”€ Automatically determines number of clusters                          â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Results:                                                                 â”‚
â”‚  â”œâ”€â”€ Cluster 0: 847 faces â†’ "Character_0000" (user names: "Luna")        â”‚
â”‚  â”œâ”€â”€ Cluster 1: 623 faces â†’ "Character_0001"                             â”‚
â”‚  â”œâ”€â”€ Cluster 2: 412 faces â†’ "Character_0002"                             â”‚
â”‚  â”œâ”€â”€ ...                                                                  â”‚
â”‚  â””â”€â”€ Noise: 1,204 faces (no cluster, outliers)                           â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  For each cluster:                                                        â”‚
â”‚  â”œâ”€â”€ Calculate centroid (mean of member embeddings)                      â”‚
â”‚  â”œâ”€â”€ Calculate distances from centroid                                   â”‚
â”‚  â””â”€â”€ Store in character_clusters table                                    â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Assign faces to clusters in face_regions table                           â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INCREMENTAL ASSIGNMENT                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  New face detected in new image                                           â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  Query: nearest cluster centroid                                          â”‚
â”‚  SELECT id, 1 - (centroid <=> $embedding) as similarity                  â”‚
â”‚  FROM character_clusters                                                  â”‚
â”‚  ORDER BY centroid <=> $embedding                                         â”‚
â”‚  LIMIT 1                                                                  â”‚
â”‚       â”‚                                                                   â”‚
â”‚       â–¼                                                                   â”‚
â”‚  If similarity > 0.75:                                                    â”‚
â”‚  â””â”€â”€ Assign to existing cluster                                          â”‚
â”‚  Else:                                                                    â”‚
â”‚  â””â”€â”€ Mark as unclustered (for next batch clustering)                     â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## GPU Memory Strategy

### Dual-GPU Allocation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GPU 0: RTX 5090 (32GB VRAM)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Luna Daemon (Persistent):                                               â”‚
â”‚  â”œâ”€â”€ SDXL VAE (~2GB)                                                    â”‚
â”‚  â”œâ”€â”€ CLIP-L ViT-L/14 (~1GB)                                             â”‚
â”‚  â””â”€â”€ CLIP-G ViT-bigG/14 (~3GB)                                          â”‚
â”‚  Subtotal: ~6GB                                                          â”‚
â”‚                                                                          â”‚
â”‚  DiffusionToolkit Embedding Service (Load on demand):                    â”‚
â”‚  â”œâ”€â”€ BGE-large-en-v1.5 (~1.5GB)                                         â”‚
â”‚  â”œâ”€â”€ CLIP-H ViT-H/14 for images (~2GB)                                  â”‚
â”‚  â””â”€â”€ YOLO Face Detector (~200MB)                                        â”‚
â”‚  Subtotal: ~4GB                                                          â”‚
â”‚                                                                          â”‚
â”‚  Available for generation: ~22GB                                         â”‚
â”‚  â””â”€â”€ Sufficient for SDXL UNet + overhead                                â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPU 1: RTX 3080 Ti (12GB VRAM)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ComfyUI Generation (uses Daemon for VAE/CLIP):                          â”‚
â”‚  â”œâ”€â”€ SDXL UNet (~6GB)                                                   â”‚
â”‚  â”œâ”€â”€ ControlNet models (1-2GB each, loaded on demand)                   â”‚
â”‚  â”œâ”€â”€ IP-Adapter (~1GB)                                                  â”‚
â”‚  â””â”€â”€ LoRAs (minimal VRAM impact)                                        â”‚
â”‚                                                                          â”‚
â”‚  Available: 12GB - models = 3-5GB headroom                               â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TTL-Based Model Unloading

```python
# Luna Daemon TTL Configuration

MODEL_TTL = {
    "vae": 300,        # 5 minutes - frequently used
    "clip_l": 300,     # 5 minutes - frequently used
    "clip_g": 300,     # 5 minutes - frequently used
    "bge": 60,         # 1 minute - only during indexing
    "clip_h": 60,      # 1 minute - only during indexing
    "yolo_face": 120,  # 2 minutes - during face detection batches
}

# Daemon tracks last-use timestamp per model
# Background thread unloads models exceeding TTL
# Re-loads on next request (small latency, big VRAM savings)
```

---

## Security Considerations

### API Access Control

```yaml
# DiffusionToolkit API Configuration

api:
  enabled: true
  host: "127.0.0.1"  # Localhost only by default
  port: 19280
  
  # Optional: Allow ComfyUI on different machine
  # allowed_origins:
  #   - "192.168.1.100"
  
  # Rate limiting
  rate_limit:
    enabled: true
    requests_per_minute: 100
    burst: 20
  
  # Endpoints can be individually enabled/disabled
  endpoints:
    images: true
    clusters: true
    wildcards: true
    controlnet: true
    captions: true
    batch: true
```

### File Path Validation

All API endpoints that accept file paths validate:
- Path is within configured watched folders
- Path exists in database (not arbitrary file access)
- User has appropriate permissions for operation

---

## Future Enhancements

### Phase 2: Advanced Analytics

- **Rating Correlation:** "What settings produce 5-star images?"
- **LoRA Effectiveness:** "Which LoRAs improve quality for this character?"
- **Prompt Pattern Mining:** "Common patterns in successful prompts"

### Phase 3: AI-Assisted Curation

- **Auto Quality Scoring:** Predict rating based on embeddings
- **Duplicate Detection:** Find near-identical images for deduplication
- **Style Clustering:** Group images by visual style (beyond faces)

### Phase 4: Distributed Processing

- **Multi-Machine:** DiffusionToolkit coordinates multiple ComfyUI instances
- **Cloud Burst:** Overflow to cloud GPU when local is busy
- **Queue Priority:** High-priority jobs (user-initiated) vs background (batch)

---

## Summary

This integration creates a **closed-loop AI image workflow**:

1. **Generate** images in ComfyUI with Luna nodes
2. **Save** with complete metadata via LunaMultiSaver
3. **Index** automatically via Diffusion.Watcher
4. **Embed** with 5-layer system for multi-modal search
5. **Discover** characters via face clustering
6. **Curate** quality ratings and training datasets
7. **Search** using any combination of embeddings
8. **Refine** via right-click â†’ ComfyUI workflows
9. **Train** LoRAs from curated character clusters
10. **Generate** better images with trained LoRAs

The result is an AI image management system that gets smarter the more you use it.

---

*Document Version: 1.0*
*Last Updated: December 2025*
*Author: DiffusionToolkit Development Team*
